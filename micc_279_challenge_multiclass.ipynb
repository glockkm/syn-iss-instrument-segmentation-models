{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "EJhh8AbxPEpc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14825,
     "status": "ok",
     "timestamp": 1701285839244,
     "user": {
      "displayName": "Kimberly Glock",
      "userId": "00419033501391390114"
     },
     "user_tz": 480
    },
    "id": "EJhh8AbxPEpc",
    "outputId": "69fa5ce0-2e8f-406b-e579-e180d14cfae3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# === IMPORTS ===\n",
    "# Import all necessary libraries for model, training, and utilities\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "# store data here for notebook access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da0f8715",
   "metadata": {
    "executionInfo": {
     "elapsed": 398,
     "status": "ok",
     "timestamp": 1701285839640,
     "user": {
      "displayName": "Kimberly Glock",
      "userId": "00419033501391390114"
     },
     "user_tz": 480
    },
    "id": "da0f8715"
   },
   "outputs": [],
   "source": [
    "# === IMPORTS ===\n",
    "# Import all necessary libraries for model, training, and utilities\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfbd4e31",
   "metadata": {
    "executionInfo": {
     "elapsed": 151,
     "status": "ok",
     "timestamp": 1701281564466,
     "user": {
      "displayName": "Kimberly Glock",
      "userId": "00419033501391390114"
     },
     "user_tz": 480
    },
    "id": "cfbd4e31"
   },
   "outputs": [],
   "source": [
    "# DO INITIALLY WHEN CONVERTING MASKS\n",
    "# path = '/content/drive/My Drive/Colab Notebooks/images_challenge_multiclass/multi_masks/'\n",
    "\n",
    "#  960 pixels in width and 540 pixels in height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbefcf35",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1701285839640,
     "user": {
      "displayName": "Kimberly Glock",
      "userId": "00419033501391390114"
     },
     "user_tz": 480
    },
    "id": "dbefcf35"
   },
   "outputs": [],
   "source": [
    "color_dict = {1: (0, 0, 0), 2: (49, 205, 49), 3: (138, 0, 0), 4: (255, 214, 0)}\n",
    "\n",
    "\n",
    "\n",
    "# Black: (0, 0, 0) background\n",
    "# Green: (49, 205, 49) jaws\n",
    "# Dark Red: (138, 0, 0) wrist\n",
    "# Yellow: (255, 214, 0) arm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb67886",
   "metadata": {
    "id": "cfb67886"
   },
   "outputs": [],
   "source": [
    "# output_path = '/content/drive/My Drive/Colab Notebooks/images_challenge_multiclass/converted_masks/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10660aaa",
   "metadata": {
    "executionInfo": {
     "elapsed": 497797,
     "status": "ok",
     "timestamp": 1701282066000,
     "user": {
      "displayName": "Kimberly Glock",
      "userId": "00419033501391390114"
     },
     "user_tz": 480
    },
    "id": "10660aaa"
   },
   "outputs": [],
   "source": [
    "# === VISUALIZATION ===\n",
    "# Visualize predictions, masks, or training outputs\n",
    "# DO ONCE TO CONVERT MASKS\n",
    "\n",
    "\n",
    "\n",
    "# for file_name in os.listdir(path):\n",
    "#     # read in the RGB mask image\n",
    "#     rgb_mask = cv2.imread(os.path.join(path, file_name))\n",
    "\n",
    "#     # create an empty multiclass mask\n",
    "#     multiclass_mask = np.zeros(rgb_mask.shape[:2], dtype=np.uint8)\n",
    "\n",
    "#     # loop through each pixel of the RGB mask image and map its color to the corresponding class label\n",
    "#     for label, color in color_dict.items():\n",
    "#         indices = np.where(np.all(rgb_mask == color, axis=-1))\n",
    "#         multiclass_mask[indices] = label\n",
    "\n",
    "#     # save the multiclass mask image\n",
    "#     output_folder = '/content/drive/My Drive/Colab Notebooks/images_challenge_multiclass/converted_masks/'\n",
    "#     cv2.imwrite(os.path.join(output_folder, f\"multiclass_mask_{file_name}\"), multiclass_mask)\n",
    "    # However, because the class labels are so low, they are not visually distinct in the grayscale image. If you want to visually inspect the multiclass mask, you may need to apply a colormap or rescale the class labels to a higher range for better visibility\n",
    "\n",
    "\n",
    "\n",
    "# multiclass_mask = np.zeros(rgb_mask.shape[:2], dtype=np.uint8)\n",
    "# this code creates a NumPy array multiclass_mask filled with zeros. the shape of the array is determined by the first two dimensions of the rgb_mask array. the dtype argument specifies the data type of the elements in the multiclass_mask array as an unsigned integer with 8 bits.\n",
    "# in particular, this code is creating a binary mask for a multiclass segmentation task, where each pixel can belong to one of several classes. the resulting multiclass_mask array will be of the same shape as the rgb_mask array, but with all elements initialized to zero. this array can then be used to mark the pixels belonging to each class by setting the corresponding elements to a non-zero value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "pLRkbMGZQKqn",
   "metadata": {
    "executionInfo": {
     "elapsed": 183,
     "status": "ok",
     "timestamp": 1701285865920,
     "user": {
      "displayName": "Kimberly Glock",
      "userId": "00419033501391390114"
     },
     "user_tz": 480
    },
    "id": "pLRkbMGZQKqn"
   },
   "outputs": [],
   "source": [
    "# === IMPORTS ===\n",
    "# Import all necessary libraries for model, training, and utilities\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# set up source and target directories\n",
    "SOURCE_DIR = '/content/drive/My Drive/Colab Notebooks/images_challenge_multiclass/'\n",
    "source_images = os.path.join(SOURCE_DIR, 'groundtruth')\n",
    "source_masks = os.path.join(SOURCE_DIR, 'converted_masks')\n",
    "\n",
    "DATA_DIR = '/content/drive/My Drive/Colab Notebooks/images_challenge_multiclass/'\n",
    "\n",
    "x_train_dir = os.path.join(DATA_DIR, 'XTrain')\n",
    "y_train_dir = os.path.join(DATA_DIR, 'yTrain')\n",
    "\n",
    "x_valid_dir = os.path.join(DATA_DIR, 'XVal')\n",
    "y_valid_dir = os.path.join(DATA_DIR, 'yVal')\n",
    "\n",
    "x_test_dir = os.path.join(DATA_DIR, 'XTest')\n",
    "y_test_dir = os.path.join(DATA_DIR, 'yTest')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "GkkzfapnRViY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28461,
     "status": "ok",
     "timestamp": 1701283070880,
     "user": {
      "displayName": "Kimberly Glock",
      "userId": "00419033501391390114"
     },
     "user_tz": 480
    },
    "id": "GkkzfapnRViY",
    "outputId": "fbb0e716-3a3f-4c20-9c4f-7ddf38b11611"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4232 images and 4191 masks.\n",
      "Total pairs matched: 4191\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def split_data(source_images, source_masks, split=(0.7, 0.2, 0.1)):\n",
    "    image_files = [f for f in os.listdir(source_images) if f.endswith('.png')]\n",
    "    mask_files = [f for f in os.listdir(source_masks) if f.endswith('.png')]\n",
    "\n",
    "    print(f\"Found {len(image_files)} images and {len(mask_files)} masks.\")\n",
    "\n",
    "    pairs = []\n",
    "    for mask in mask_files:\n",
    "        # extract the unique ID from the mask filename\n",
    "        unique_id = mask.replace('multiclass_mask_p-', '').replace('.png', '')\n",
    "        corresponding_image = f\"s-{unique_id}.png\"\n",
    "\n",
    "        if corresponding_image in image_files:\n",
    "            pairs.append((os.path.join(source_images, corresponding_image), os.path.join(source_masks, mask)))\n",
    "\n",
    "    print(f\"Total pairs matched: {len(pairs)}\")\n",
    "\n",
    "    random.shuffle(pairs)\n",
    "\n",
    "    train_idx = int(len(pairs) * split[0])\n",
    "    valid_idx = train_idx + int(len(pairs) * split[1])\n",
    "\n",
    "    for i, (img_path, mask_path) in enumerate(pairs):\n",
    "        try:\n",
    "            if i < train_idx:\n",
    "                shutil.move(img_path, x_train_dir)\n",
    "                shutil.move(mask_path, y_train_dir)\n",
    "            elif i < valid_idx:\n",
    "                shutil.move(img_path, x_valid_dir)\n",
    "                shutil.move(mask_path, y_valid_dir)\n",
    "            else:\n",
    "                shutil.move(img_path, x_test_dir)\n",
    "                shutil.move(mask_path, y_test_dir)\n",
    "        except Exception as e:\n",
    "            print(f\"Error moving file: {e}\")\n",
    "\n",
    "# execute the split\n",
    "split_data(source_images, source_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "001bda48",
   "metadata": {
    "executionInfo": {
     "elapsed": 167,
     "status": "ok",
     "timestamp": 1701285876127,
     "user": {
      "displayName": "Kimberly Glock",
      "userId": "00419033501391390114"
     },
     "user_tz": 480
    },
    "id": "001bda48"
   },
   "outputs": [],
   "source": [
    "# === IMPORTS ===\n",
    "# Import all necessary libraries for model, training, and utilities\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "# controls the verbosity level of TensorFlow logging messages, and setting it to different values adjusts the amount of logging information that TensorFlow prints to the console\n",
    "# \"2\": filters out both info and warning messages, only displaying error messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "lmg2EKqVhoZu",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7668,
     "status": "ok",
     "timestamp": 1701285884870,
     "user": {
      "displayName": "Kimberly Glock",
      "userId": "00419033501391390114"
     },
     "user_tz": 480
    },
    "id": "lmg2EKqVhoZu",
    "outputId": "af75a97c-d9b7-47eb-d205-30a29208e6e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 540, 960, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " zero_padding2d (ZeroPaddin  (None, 544, 960, 3)          0         ['input_1[0][0]']             \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 544, 960, 64)         1792      ['zero_padding2d[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (None, 544, 960, 64)         256       ['conv2d[0][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation (Activation)     (None, 544, 960, 64)         0         ['batch_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 544, 960, 64)         36928     ['activation[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_1 (Bat  (None, 544, 960, 64)         256       ['conv2d_1[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_1 (Activation)   (None, 544, 960, 64)         0         ['batch_normalization_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2  (None, 272, 480, 64)         0         ['activation_1[0][0]']        \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 272, 480, 128)        73856     ['max_pooling2d[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_2 (Bat  (None, 272, 480, 128)        512       ['conv2d_2[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_2 (Activation)   (None, 272, 480, 128)        0         ['batch_normalization_2[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (None, 272, 480, 128)        147584    ['activation_2[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_3 (Bat  (None, 272, 480, 128)        512       ['conv2d_3[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_3 (Activation)   (None, 272, 480, 128)        0         ['batch_normalization_3[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPoolin  (None, 136, 240, 128)        0         ['activation_3[0][0]']        \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)           (None, 136, 240, 256)        295168    ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_4 (Bat  (None, 136, 240, 256)        1024      ['conv2d_4[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_4 (Activation)   (None, 136, 240, 256)        0         ['batch_normalization_4[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)           (None, 136, 240, 256)        590080    ['activation_4[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_5 (Bat  (None, 136, 240, 256)        1024      ['conv2d_5[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_5 (Activation)   (None, 136, 240, 256)        0         ['batch_normalization_5[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPoolin  (None, 68, 120, 256)         0         ['activation_5[0][0]']        \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)           (None, 68, 120, 512)         1180160   ['max_pooling2d_2[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_6 (Bat  (None, 68, 120, 512)         2048      ['conv2d_6[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_6 (Activation)   (None, 68, 120, 512)         0         ['batch_normalization_6[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)           (None, 68, 120, 512)         2359808   ['activation_6[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_7 (Bat  (None, 68, 120, 512)         2048      ['conv2d_7[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_7 (Activation)   (None, 68, 120, 512)         0         ['batch_normalization_7[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPoolin  (None, 34, 60, 512)          0         ['activation_7[0][0]']        \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)           (None, 34, 60, 1024)         4719616   ['max_pooling2d_3[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_8 (Bat  (None, 34, 60, 1024)         4096      ['conv2d_8[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_8 (Activation)   (None, 34, 60, 1024)         0         ['batch_normalization_8[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)           (None, 34, 60, 1024)         9438208   ['activation_8[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_9 (Bat  (None, 34, 60, 1024)         4096      ['conv2d_9[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_9 (Activation)   (None, 34, 60, 1024)         0         ['batch_normalization_9[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTr  (None, 68, 120, 512)         2097664   ['activation_9[0][0]']        \n",
      " anspose)                                                                                         \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 68, 120, 1024)        0         ['conv2d_transpose[0][0]',    \n",
      "                                                                     'activation_7[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)          (None, 68, 120, 512)         4719104   ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_10 (Ba  (None, 68, 120, 512)         2048      ['conv2d_10[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_10 (Activation)  (None, 68, 120, 512)         0         ['batch_normalization_10[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)          (None, 68, 120, 512)         2359808   ['activation_10[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_11 (Ba  (None, 68, 120, 512)         2048      ['conv2d_11[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_11 (Activation)  (None, 68, 120, 512)         0         ['batch_normalization_11[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2D  (None, 136, 240, 256)        524544    ['activation_11[0][0]']       \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 136, 240, 512)        0         ['conv2d_transpose_1[0][0]',  \n",
      " )                                                                   'activation_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)          (None, 136, 240, 256)        1179904   ['concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_12 (Ba  (None, 136, 240, 256)        1024      ['conv2d_12[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_12 (Activation)  (None, 136, 240, 256)        0         ['batch_normalization_12[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)          (None, 136, 240, 256)        590080    ['activation_12[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_13 (Ba  (None, 136, 240, 256)        1024      ['conv2d_13[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_13 (Activation)  (None, 136, 240, 256)        0         ['batch_normalization_13[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2D  (None, 272, 480, 128)        131200    ['activation_13[0][0]']       \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate  (None, 272, 480, 256)        0         ['conv2d_transpose_2[0][0]',  \n",
      " )                                                                   'activation_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)          (None, 272, 480, 128)        295040    ['concatenate_2[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_14 (Ba  (None, 272, 480, 128)        512       ['conv2d_14[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_14 (Activation)  (None, 272, 480, 128)        0         ['batch_normalization_14[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)          (None, 272, 480, 128)        147584    ['activation_14[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_15 (Ba  (None, 272, 480, 128)        512       ['conv2d_15[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_15 (Activation)  (None, 272, 480, 128)        0         ['batch_normalization_15[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_transpose_3 (Conv2D  (None, 544, 960, 64)         32832     ['activation_15[0][0]']       \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate  (None, 544, 960, 128)        0         ['conv2d_transpose_3[0][0]',  \n",
      " )                                                                   'activation_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)          (None, 544, 960, 64)         73792     ['concatenate_3[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_16 (Ba  (None, 544, 960, 64)         256       ['conv2d_16[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_16 (Activation)  (None, 544, 960, 64)         0         ['batch_normalization_16[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)          (None, 544, 960, 64)         36928     ['activation_16[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_17 (Ba  (None, 544, 960, 64)         256       ['conv2d_17[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_17 (Activation)  (None, 544, 960, 64)         0         ['batch_normalization_17[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)          (None, 544, 960, 4)          260       ['activation_17[0][0]']       \n",
      "                                                                                                  \n",
      " cropping2d (Cropping2D)     (None, 540, 960, 4)          0         ['conv2d_18[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 31055492 (118.47 MB)\n",
      "Trainable params: 31043716 (118.42 MB)\n",
      "Non-trainable params: 11776 (46.00 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# === IMPORTS ===\n",
    "# Import all necessary libraries for model, training, and utilities\n",
    "from keras.models import Model\n",
    "from keras.layers import (Input, Conv2D, BatchNormalization, Activation,\n",
    "                          MaxPool2D, Conv2DTranspose, Concatenate, ZeroPadding2D, Cropping2D)\n",
    "\n",
    "def conv_block(inputs, num_filters):\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def encoder_block(inputs, num_filters):\n",
    "    x = conv_block(inputs, num_filters)\n",
    "    p = MaxPool2D((2, 2))(x)\n",
    "    return x, p\n",
    "\n",
    "def decoder_block(inputs, skip, num_filters):\n",
    "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(inputs)\n",
    "    x = Concatenate()([x, skip])\n",
    "    x = conv_block(x, num_filters)\n",
    "    return x\n",
    "\n",
    "def build_unet(input_shape, num_classes):\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    # padding for input_shape to be divisible by 2^4\n",
    "    pad_height = (16 - input_shape[0] % 16) % 16\n",
    "    pad_width = (16 - input_shape[1] % 16) % 16\n",
    "    x = ZeroPadding2D(padding=((pad_height // 2, pad_height - pad_height // 2),\n",
    "                               (pad_width // 2, pad_width - pad_width // 2)))(inputs)\n",
    "\n",
    "    s1, p1 = encoder_block(x, 64)\n",
    "    s2, p2 = encoder_block(p1, 128)\n",
    "    s3, p3 = encoder_block(p2, 256)\n",
    "    s4, p4 = encoder_block(p3, 512)\n",
    "\n",
    "    b1 = conv_block(p4, 1024)\n",
    "\n",
    "    d1 = decoder_block(b1, s4, 512)\n",
    "    d2 = decoder_block(d1, s3, 256)\n",
    "    d3 = decoder_block(d2, s2, 128)\n",
    "    d4 = decoder_block(d3, s1, 64)\n",
    "\n",
    "    outputs = Conv2D(num_classes, 1, padding=\"same\", activation=\"softmax\")(d4)\n",
    "\n",
    "    # calculate cropping size and crop the output\n",
    "    crop_height = pad_height // 2\n",
    "    crop_width = pad_width // 2\n",
    "    outputs = Cropping2D(cropping=((crop_height, crop_height), (crop_width, crop_width)))(outputs)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_shape = (540, 960, 3)  # original input shape\n",
    "    num_classes = 4  # set the number of classes as needed\n",
    "    model = build_unet(input_shape, num_classes)\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "019d9773",
   "metadata": {
    "executionInfo": {
     "elapsed": 169,
     "status": "ok",
     "timestamp": 1701285890898,
     "user": {
      "displayName": "Kimberly Glock",
      "userId": "00419033501391390114"
     },
     "user_tz": 480
    },
    "id": "019d9773"
   },
   "outputs": [],
   "source": [
    "# === IMPORTS ===\n",
    "# Import all necessary libraries for model, training, and utilities\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, CSVLogger\n",
    "global image_h\n",
    "global image_w\n",
    "global num_classes\n",
    "global classes\n",
    "global rgb_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8539c69",
   "metadata": {
    "executionInfo": {
     "elapsed": 190,
     "status": "ok",
     "timestamp": 1701285893256,
     "user": {
      "displayName": "Kimberly Glock",
      "userId": "00419033501391390114"
     },
     "user_tz": 480
    },
    "id": "f8539c69"
   },
   "outputs": [],
   "source": [
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ehZjjgYmbrhU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8709948,
     "status": "ok",
     "timestamp": 1701294609379,
     "user": {
      "displayName": "Kimberly Glock",
      "userId": "00419033501391390114"
     },
     "user_tz": 480
    },
    "id": "ehZjjgYmbrhU",
    "outputId": "ea71da40-9635-4a15-c020-9b5a20b99d00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 2933/2933 - Valid: 838/838 - Test: 420/420\n",
      "\n",
      "Epoch 1/5\n",
      "978/978 [==============================] - ETA: 0s - loss: 0.1177\n",
      "Epoch 1: val_loss improved from inf to 0.04348, saving model to files/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "978/978 [==============================] - 1829s 2s/step - loss: 0.1177 - val_loss: 0.0435 - lr: 1.0000e-04\n",
      "Epoch 2/5\n",
      "978/978 [==============================] - ETA: 0s - loss: 0.0259\n",
      "Epoch 2: val_loss improved from 0.04348 to 0.02526, saving model to files/model.h5\n",
      "978/978 [==============================] - 1731s 2s/step - loss: 0.0259 - val_loss: 0.0253 - lr: 1.0000e-04\n",
      "Epoch 3/5\n",
      "978/978 [==============================] - ETA: 0s - loss: 0.0155\n",
      "Epoch 3: val_loss improved from 0.02526 to 0.01816, saving model to files/model.h5\n",
      "978/978 [==============================] - 1678s 2s/step - loss: 0.0155 - val_loss: 0.0182 - lr: 1.0000e-04\n",
      "Epoch 4/5\n",
      "978/978 [==============================] - ETA: 0s - loss: 0.0107\n",
      "Epoch 4: val_loss improved from 0.01816 to 0.01233, saving model to files/model.h5\n",
      "978/978 [==============================] - 1679s 2s/step - loss: 0.0107 - val_loss: 0.0123 - lr: 1.0000e-04\n",
      "Epoch 5/5\n",
      "978/978 [==============================] - ETA: 0s - loss: 0.0098\n",
      "Epoch 5: val_loss improved from 0.01233 to 0.00867, saving model to files/model.h5\n",
      "978/978 [==============================] - 1677s 2s/step - loss: 0.0098 - val_loss: 0.0087 - lr: 1.0000e-04\n",
      "Model saved at files/multiclass_challenge_model.h5\n"
     ]
    }
   ],
   "source": [
    "# === IMPORTS ===\n",
    "# Import all necessary libraries for model, training, and utilities\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger, EarlyStopping\n",
    "from glob import glob\n",
    "\n",
    "def preprocess(image_path, mask_path):\n",
    "    # read and preprocess the image\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_png(image, channels=3)\n",
    "    image = tf.image.resize(image, [image_h, image_w])\n",
    "    image = image / 255.0\n",
    "\n",
    "    # read and preprocess the mask\n",
    "    mask = tf.io.read_file(mask_path)\n",
    "    mask = tf.image.decode_png(mask, channels=1)\n",
    "    mask = tf.image.resize(mask, [image_h, image_w])\n",
    "    mask = tf.squeeze(mask)  # ensure mask is a 2D image\n",
    "    mask = tf.cast(mask, tf.int32)\n",
    "    mask = tf.one_hot(mask, num_classes, axis=-1)\n",
    "\n",
    "    return image, mask\n",
    "\n",
    "def tf_dataset(X, Y, batch=3):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((X, Y))\n",
    "    ds = ds.shuffle(buffer_size=5000).map(preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    ds = ds.batch(batch).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "def load_dataset(base_dataset_path):\n",
    "    train_x = sorted(glob(os.path.join(base_dataset_path, 'XTrain', \"*.png\")))\n",
    "    train_y = sorted(glob(os.path.join(base_dataset_path, 'yTrain', \"*.png\")))\n",
    "\n",
    "    valid_x = sorted(glob(os.path.join(base_dataset_path, 'XVal', \"*.png\")))\n",
    "    valid_y = sorted(glob(os.path.join(base_dataset_path, 'yVal', \"*.png\")))\n",
    "\n",
    "    test_x = sorted(glob(os.path.join(base_dataset_path, 'XTest', \"*.png\")))\n",
    "    test_y = sorted(glob(os.path.join(base_dataset_path, 'yTest', \"*.png\")))\n",
    "\n",
    "    return (train_x, train_y), (valid_x, valid_y), (test_x, test_y)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\" seeding \"\"\"\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "\n",
    "    \"\"\" directory for storing files \"\"\"\n",
    "    create_dir(\"files\")\n",
    "\n",
    "    \"\"\" hyperparameters \"\"\"\n",
    "    image_h = 540\n",
    "    image_w = 960\n",
    "    num_classes = 4\n",
    "    input_shape = (image_h, image_w, 3)\n",
    "    batch_size = 3\n",
    "    lr = 1e-4\n",
    "    num_epochs = 5\n",
    "\n",
    "    \"\"\" paths \"\"\"\n",
    "    base_dataset_path = \"/content/drive/My Drive/Colab Notebooks/images_challenge_multiclass/\"\n",
    "    model_path = os.path.join(\"files\", \"model.h5\")\n",
    "    csv_path = os.path.join(\"files\", \"data.csv\")\n",
    "\n",
    "    \"\"\" loading the dataset \"\"\"\n",
    "    (train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_dataset(base_dataset_path)\n",
    "    print(f\"Train: {len(train_x)}/{len(train_y)} - Valid: {len(valid_x)}/{len(valid_y)} - Test: {len(test_x)}/{len(test_y)}\")\n",
    "    print(\"\")\n",
    "\n",
    "    \"\"\" dataset pipeline \"\"\"\n",
    "    train_ds = tf_dataset(train_x, train_y, batch=batch_size)\n",
    "    valid_ds = tf_dataset(valid_x, valid_y, batch=batch_size)\n",
    "\n",
    "    \"\"\" model \"\"\"\n",
    "    model = build_unet(input_shape, num_classes)\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(lr))\n",
    "\n",
    "    \"\"\" training \"\"\"\n",
    "    callbacks = [\n",
    "        ModelCheckpoint(model_path, verbose=1, save_best_only=True, monitor='val_loss'),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-7, verbose=1),\n",
    "        CSVLogger(csv_path, append=True),\n",
    "        EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=False)\n",
    "    ]\n",
    "\n",
    "    model.fit(train_ds, validation_data=valid_ds, epochs=num_epochs, callbacks=callbacks)\n",
    "\n",
    "    # save the final model state\n",
    "    final_model_path = os.path.join(\"files\", \"multiclass_challenge_model.h5\")\n",
    "    model.save(final_model_path)\n",
    "    print(f\"Model saved at {final_model_path}\")\n",
    "\n",
    "\n",
    "# files/model.h5/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079\n",
    "# https://colab.research.google.com/signup/pricing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1Tcxd6XlIo6x",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 171,
     "status": "ok",
     "timestamp": 1701295874271,
     "user": {
      "displayName": "Kimberly Glock",
      "userId": "00419033501391390114"
     },
     "user_tz": 480
    },
    "id": "1Tcxd6XlIo6x",
    "outputId": "06ff3609-4dfa-49b0-ade5-75d1cf3de0ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: /content\n"
     ]
    }
   ],
   "source": [
    "print(\"Current Working Directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "et030ZvsI9n-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 162,
     "status": "ok",
     "timestamp": 1701295941028,
     "user": {
      "displayName": "Kimberly Glock",
      "userId": "00419033501391390114"
     },
     "user_tz": 480
    },
    "id": "et030ZvsI9n-",
    "outputId": "50050182-f783-4801-dbe8-19f4263043fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'files' directory exists at: /content/files\n",
      "Files in 'files' directory: ['multiclass_challenge_model.h5', 'model.h5', 'data.csv']\n"
     ]
    }
   ],
   "source": [
    "files_dir = os.path.join(os.getcwd(), \"files\")\n",
    "if os.path.exists(files_dir):\n",
    "    print(f\"'files' directory exists at: {files_dir}\")\n",
    "    # list files in the 'files' directory\n",
    "    print(\"Files in 'files' directory:\", os.listdir(files_dir))\n",
    "else:\n",
    "    print(f\"'files' directory does not exist at: {files_dir}\")\n",
    "\n",
    "    # not seeing these files in your Google Drive is that /content is a directory on the Colab virtual machine, not in your Google Drive. Files saved here are stored temporarily on the Colab VM and are not automatically synchronized with your Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6gcnDeMMJ8rJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3725,
     "status": "ok",
     "timestamp": 1701296261066,
     "user": {
      "displayName": "Kimberly Glock",
      "userId": "00419033501391390114"
     },
     "user_tz": 480
    },
    "id": "6gcnDeMMJ8rJ",
    "outputId": "55a7d163-cbac-485c-f071-444a0876b5bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied multiclass_challenge_model.h5 to /content/drive/My Drive/Colab Notebooks/images_challenge_multiclass/files/\n",
      "Copied model.h5 to /content/drive/My Drive/Colab Notebooks/images_challenge_multiclass/files/\n",
      "Copied data.csv to /content/drive/My Drive/Colab Notebooks/images_challenge_multiclass/files/\n"
     ]
    }
   ],
   "source": [
    "# === IMPORTS ===\n",
    "# Import all necessary libraries for model, training, and utilities\n",
    "import shutil\n",
    "\n",
    "# specify google Drive path\n",
    "drive_target_path = '/content/drive/My Drive/Colab Notebooks/images_challenge_multiclass/files/'\n",
    "\n",
    "# create target directory in Google Drive if it doesn't exist\n",
    "os.makedirs(drive_target_path, exist_ok=True)\n",
    "\n",
    "# copy files from '/content/files' to the Google Drive directory\n",
    "for file_name in os.listdir(files_dir):\n",
    "    shutil.copy(os.path.join(files_dir, file_name), drive_target_path)\n",
    "    print(f\"Copied {file_name} to {drive_target_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zHM_dB-7kRSL",
   "metadata": {
    "id": "zHM_dB-7kRSL"
   },
   "outputs": [],
   "source": [
    "##################################### TEST THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uIUWf3kLkTUv",
   "metadata": {
    "id": "uIUWf3kLkTUv"
   },
   "outputs": [],
   "source": [
    "# === IMPORTS ===\n",
    "# Import all necessary libraries for model, training, and utilities\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# function to preprocess images (similar to training preprocessing)\n",
    "def preprocess_image(image_path, image_h, image_w):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_png(image, channels=3)\n",
    "    image = tf.image.resize(image, [image_h, image_w])\n",
    "    image = image / 255.0\n",
    "    return image\n",
    "\n",
    "# function to save mask to a file\n",
    "def save_mask(mask, save_path):\n",
    "    mask = np.argmax(mask, axis=-1)\n",
    "    mask = (mask * 255).astype(np.uint8)\n",
    "    cv2.imwrite(save_path, mask)\n",
    "\n",
    "# load the model\n",
    "model_path = \"/path/to/saved/model.h5\"\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "# set parameters\n",
    "image_h, image_w = 540, 960  # same as during training\n",
    "test_images_path = \"/path/to/test/images/\"\n",
    "output_masks_path = \"/path/to/save/masks/\"\n",
    "\n",
    "# create output directory if it doesn't exist\n",
    "if not os.path.exists(output_masks_path):\n",
    "    os.makedirs(output_masks_path)\n",
    "\n",
    "# process each test image\n",
    "for image_file in glob(os.path.join(test_images_path, \"*.png\")):\n",
    "    # preprocess the image\n",
    "    image = preprocess_image(image_file, image_h, image_w)\n",
    "    image = np.expand_dims(image, axis=0)  # add batch dimension\n",
    "\n",
    "    # predict mask\n",
    "    predicted_mask = model.predict(image)\n",
    "\n",
    "    # post-process and save mask\n",
    "    mask_filename = os.path.basename(image_file).replace('.png', '_mask.png')\n",
    "    save_mask_path = os.path.join(output_masks_path, mask_filename)\n",
    "    save_mask(predicted_mask[0], save_mask_path)  # [0] to remove batch dimension\n",
    "\n",
    "    print(f\"Mask saved to: {save_mask_path}\")\n",
    "\n",
    "\n",
    "\n",
    "# Update model_path, test_images_path, and output_masks_path with the appropriate paths.\n",
    "# The preprocess_image function should mirror the preprocessing done during training.\n",
    "# The save_mask function converts the predicted mask (assuming one-hot encoded output) back to a single-channel image and saves it.\n",
    "# The script processes each image in the test images directory, predicts the mask, and saves it in the specified output directory.\n",
    "# This script assumes that the saved model outputs a one-hot encoded mask. If your model's output format is different, you will need to modify the save_mask function accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93o0xHT2lqLy",
   "metadata": {
    "id": "93o0xHT2lqLy"
   },
   "outputs": [],
   "source": [
    "# load this model later using tf.keras.models.load_model(final_model_path) for further usage or testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d790b6",
   "metadata": {
    "id": "d1d790b6"
   },
   "outputs": [],
   "source": [
    "##################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaad3048",
   "metadata": {
    "id": "aaad3048"
   },
   "outputs": [],
   "source": [
    "# TEST MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802768da",
   "metadata": {
    "id": "802768da"
   },
   "outputs": [],
   "source": [
    "# === IMPORTS ===\n",
    "# Import all necessary libraries for model, training, and utilities\n",
    "# import numpy as np\n",
    "# import cv2\n",
    "# import pandas as pd\n",
    "# from glob import glob\n",
    "# from tqdm import tqdm\n",
    "# import tensorflow as tf\n",
    "# from sklearn.metrics import f1_score, jaccard_score\n",
    "# # from train import create_dir, load_dataset: use when train is it's own notebook\n",
    "\n",
    "# import os\n",
    "# os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093c1d65",
   "metadata": {
    "id": "093c1d65"
   },
   "outputs": [],
   "source": [
    "# def grayscale_to_rgb(mask, rgb_codes):\n",
    "#     h, w = mask.shape[0], mask.shape[1]\n",
    "#     mask = mask.astype(np.int32)\n",
    "#     output = []\n",
    "\n",
    "#     for i, pixel in enumerate(mask.flatten()):\n",
    "#         output.append(rgb_codes[pixel])\n",
    "\n",
    "#     output = np.reshape(output, (h, w, 3))\n",
    "#     return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a88650",
   "metadata": {
    "id": "92a88650"
   },
   "outputs": [],
   "source": [
    "# === VISUALIZATION ===\n",
    "# Visualize predictions, masks, or training outputs\n",
    "# def save_results(image_x, mask, pred, save_image_path):\n",
    "#     mask = np.expand_dims(mask, axis=-1)\n",
    "#     mask = grayscale_to_rgb(mask, rgb_codes)\n",
    "\n",
    "#     pred = np.expand_dims(pred, axis=-1)\n",
    "#     pred = grayscale_to_rgb(pred, rgb_codes)\n",
    "\n",
    "#     line = np.ones((image_x.shape[0], 10, 3)) * 255\n",
    "\n",
    "#     cat_images = np.concatenate([image_x, line, mask, line, pred], axis=1)\n",
    "#     cv2.imwrite(save_image_path, cat_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef77676",
   "metadata": {
    "id": "9ef77676",
    "outputId": "1d280be3-1730-4e01-cc56-30288bbfb41a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1241/1241 - Valid: 100/100 - Test: 10/10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:20<00:00,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class           F1         Jaccard   \n",
      "-----------------------------------\n",
      "background     : 0.99654 - 0.99310\n",
      "shaft          : 0.99911 - 0.99823\n",
      "end-effector   : 0.98329 - 0.96716\n",
      "-----------------------------------\n",
      "Mean           : 0.99298 - 0.98616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# === TRAINING LOOP ===\n",
    "# Iterate through epochs to train and validate model performance\n",
    "# if __name__ == \"__main__\":\n",
    "#     \"\"\" seeding \"\"\"\n",
    "#     np.random.seed(42)\n",
    "#     tf.random.set_seed(42)\n",
    "\n",
    "#     \"\"\" directory for storing files \"\"\"\n",
    "#     create_dir(\"results\")\n",
    "\n",
    "#     \"\"\" hyperparameters \"\"\"\n",
    "#     image_h = 512\n",
    "#     image_w = 512\n",
    "#     num_classes = 3\n",
    "\n",
    "#     \"\"\" paths \"\"\"\n",
    "#     dataset_path = \"USE\"\n",
    "#     model_path = os.path.join(\"files\", \"model.h5\")\n",
    "\n",
    "#     \"\"\" RGB code and classes \"\"\"\n",
    "#     rgb_codes = [\n",
    "#         [0, 0, 0], [255, 214, 0], [49, 205, 49]\n",
    "#     ]\n",
    "\n",
    "\n",
    "#     classes = [\n",
    "#         \"background\", \"shaft\", \"end-effector\"\n",
    "#     ]\n",
    "\n",
    "#     \"\"\" loading the dataset \"\"\"\n",
    "#     (train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_dataset(dataset_path)\n",
    "#     print(f\"Train: {len(train_x)}/{len(train_y)} - Valid: {len(valid_x)}/{len(valid_y)} - Test: {len(test_x)}/{len(test_x)}\")\n",
    "#     print(\"\")\n",
    "\n",
    "#     \"\"\" load the saved model \"\"\"\n",
    "#     model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "#     \"\"\" prediction & evaluation \"\"\"\n",
    "#     SCORE = []\n",
    "#     for x, y in tqdm(zip(test_x, test_y), total=len(test_x)):\n",
    "#         \"\"\" extract the name \"\"\"\n",
    "#         name = x.split(\" \")[1] #[-1].split(\".\")[0] #.split(\" \")[-1] #.split(\"_\")[-1] #[0]\n",
    "\n",
    "#         \"\"\" reading the image \"\"\"\n",
    "#         image = cv2.imread(x, cv2.IMREAD_COLOR) # from test x\n",
    "#         image = cv2.resize(image, (image_w, image_h))\n",
    "#         image_x = image\n",
    "#         image = image/255.0 # (H, W, 3) normalizes\n",
    "#         image = np.expand_dims(image, axis=0) # [1, H, W, 3]\n",
    "#         image = image.astype(np.float32)\n",
    "\n",
    "#         \"\"\" reading the mask \"\"\"\n",
    "#         mask = cv2.imread(y, cv2.IMREAD_GRAYSCALE) # from test y\n",
    "#         mask = cv2.resize(mask, (image_w, image_h))\n",
    "#         mask = mask.astype(np.int32)\n",
    "\n",
    "#         \"\"\" prediction \"\"\"\n",
    "#         pred = model.predict(image, verbose=0)[0]\n",
    "#         pred = np.argmax(pred, axis=-1) # [0.1, 0.2, 0.1, 0.6] -> 3\n",
    "#         pred = pred.astype(np.int32)\n",
    "\n",
    "\n",
    "#         \"\"\" save the results \"\"\"\n",
    "#         save_image_path = f\"results/{name}.png\"\n",
    "#         save_results(image_x, mask, pred, save_image_path)\n",
    "\n",
    "\n",
    "#         \"\"\" flatten the array \"\"\"\n",
    "#         mask = mask.flatten()\n",
    "#         pred = pred.flatten()\n",
    "\n",
    "#         labels = [i for i in range(num_classes)]\n",
    "\n",
    "#         \"\"\" calculating the metrics values \"\"\"\n",
    "#         f1_value = f1_score(mask, pred, labels=labels, average=None, zero_division=0)\n",
    "#         jac_value = jaccard_score(mask, pred, labels=labels, average=None, zero_division=0)\n",
    "\n",
    "#         SCORE.append([f1_value, jac_value])\n",
    "\n",
    "#     score = np.array(SCORE)\n",
    "#     score = np.mean(score, axis=0)\n",
    "\n",
    "#     f = open(\"files/score.csv\", \"w\")\n",
    "#     f.write(\"Class,F1,Jaccard\\n\")\n",
    "\n",
    "#     l = [\"Class\", \"F1\", \"Jaccard\"]\n",
    "#     print(f\"{l[0]:15s} {l[1]:10s} {l[2]:10s}\")\n",
    "#     print(\"-\"*35)\n",
    "\n",
    "#     for i in range(num_classes):\n",
    "#         class_name = classes[i]\n",
    "#         f1 = score[0, i]\n",
    "#         jac = score[1, i]\n",
    "#         dstr = f\"{class_name:15s}: {f1:1.5f} - {jac:1.5f}\"\n",
    "#         print(dstr)\n",
    "#         f.write(f\"{class_name:15s},{f1:1.5f},{jac:1.5f}\\n\")\n",
    "\n",
    "#     print(\"-\"*35)\n",
    "#     class_mean = np.mean(score, axis=-1)\n",
    "#     class_name = \"Mean\"\n",
    "\n",
    "#     f1 = class_mean[0]\n",
    "#     jac = class_mean[1]\n",
    "\n",
    "#     dstr = f\"{class_name:15s}: {f1:1.5f} - {jac:1.5f}\"\n",
    "#     print(dstr)\n",
    "#     f.write(f\"{class_name:15s},{f1:1.5f},{jac:1.5f}\\n\")\n",
    "\n",
    "#     f.close()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
